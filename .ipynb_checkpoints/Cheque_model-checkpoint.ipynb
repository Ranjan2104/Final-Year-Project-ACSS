{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c777a4f9-7d51-4fbc-aa08-94f9eb8e64b1",
   "metadata": {},
   "source": [
    "# Image Processing and NLP Model for Project ACSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25058f65-2e19-4e98-9b98-15706b11d027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cca13aa5-c4c2-45b3-98d9-84fb1fc1981d",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.2) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-unptbv1s\\opencv\\modules\\highgui\\src\\window.cpp:404: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f673ced1bba9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'img3.jpg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Image'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.2) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-unptbv1s\\opencv\\modules\\highgui\\src\\window.cpp:404: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('img3.jpg', 0)\n",
    "cv2.imshow('Image', img)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7304077b-402e-462e-a453-a01216535e45",
   "metadata": {},
   "source": [
    "# Pay Finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dbf2bf-a877-4441-bbea-86cddf997f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_1 = img[92:120, 0:650]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eadcefb-90ca-4a39-9b4a-93f919346833",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(crop_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f93de1-d773-424a-b9f9-14988e23f2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('pay.jpg', crop_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0548fe2-ae5f-45e7-aa0c-3a02a1f9b97e",
   "metadata": {},
   "source": [
    "# Rupees in Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927ff9b5-9f71-4c26-baff-3fc98eb09f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_2 = img[120:200, 0:650]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dea48e-335e-4a06-bf60-32ea145863e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(crop_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746cdaf0-4e93-4001-839a-1578c0b3fb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('ruppes_in_word.jpg', crop_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebf653b-7a9e-4d97-bedb-c671ff1a78e2",
   "metadata": {},
   "source": [
    "# Account Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85145c05-1f24-42f4-834f-6a2e63124c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_3 = img[205:280, 110:370]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aad8237-b9eb-48df-8885-f4b40f2512b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(crop_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5475742-64f2-481f-8749-9d26ba18866d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('account_no.jpg', crop_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65421a12-d5db-40b7-8e45-d78c2ce59d14",
   "metadata": {},
   "source": [
    "# Signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a7310a-5c40-437a-86c0-7351df20d63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_4 = img[250:330, 760:950]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78aade19-364c-4804-9024-14835e111bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(crop_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1d636c-3855-4b4d-9fd2-3eca948b5dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('sign.jpg', crop_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6293c9b-5b21-44cc-8744-8d02eded1c59",
   "metadata": {},
   "source": [
    "# Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4bf769-2903-4f9b-bbbe-6e6973d424ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_5 = img[19:55, 780:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf15531-63fa-4450-9beb-974642cd3b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(crop_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e636a70c-934e-4ab8-a053-aeebecdb2cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('date.jpg', crop_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe84977e-ac88-430f-93ab-5d78b9292878",
   "metadata": {},
   "source": [
    "# Rupees in Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46139146-df6a-4387-87b4-d0027ec32eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_6 = img[150:210, 780:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2216f0d4-6d7e-411a-826a-1bc837f7b8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(crop_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f2b26c-e1e0-4e7e-9bb2-838eb6eb4092",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('rupee_in_digit.jpg', crop_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e1beaa-2364-4a54-bab9-2d1d847b035e",
   "metadata": {},
   "source": [
    "# Cheque Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689f0de4-35ea-4417-ad31-713b39bf562d",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_7 = img[400:, 550:665]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbb33fe-43ce-402b-965a-27e0c7d34ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(crop_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4857a77-0041-43de-a346-72c1ac2d6187",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('cheque_no.jpg', crop_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a5e565-0eea-4619-9fcf-9f7d85529126",
   "metadata": {},
   "source": [
    "# Preprocessing of Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52cf063-2d83-49cb-9d34-e8c71097ad77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from pytesseract import pytesseract\n",
    "\n",
    "pytesseract.tesseract_cmd = \"C:\\\\Users\\\\Amresh Ranjan\\\\Desktop\\\\WEB DEVLOPS\\\\Image to Text Project\\\\tesseract.exe\"\n",
    "\n",
    "img_1 = cv2.imread(\"account_no.jpg\")\n",
    "word_1 = pytesseract.image_to_string(img_1)\n",
    "\n",
    "img_2 = cv2.imread(\"cheque_no.jpg\")\n",
    "word_2 = pytesseract.image_to_string(img_2)\n",
    "\n",
    "img_3 = cv2.imread(\"date.jpg\")\n",
    "word_3 = pytesseract.image_to_string(img_3)\n",
    "\n",
    "img_4 = cv2.imread(\"pay.jpg\")\n",
    "word_4 = pytesseract.image_to_string(img_4)\n",
    "\n",
    "img_5 = cv2.imread(\"rupee_in_digit.jpg\")\n",
    "word_5 = pytesseract.image_to_string(img_5)\n",
    "\n",
    "img_6 = cv2.imread(\"ruppes_in_word.jpg\")\n",
    "word_6 = pytesseract.image_to_string(img_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93444d9-d08f-4b23-ba1a-1e61ad6172dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save this model in o/p.\n",
    "\n",
    "l1 = {'Account Number ' : word_1, 'Cheque Number ' : word_2, 'Date ' : word_3, \n",
    "\t\t'Payer ' : word_4, 'Ruppes in Digits ' : word_5, 'Ruppes in Word ' : word_6}\n",
    "with open(\"data.txt\", 'w') as f: \n",
    "    for key, value in l1.items(): \n",
    "        f.write('%s:%s\\n' % (key, value))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
